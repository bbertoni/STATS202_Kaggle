---
title: "Kaggle Project"
author: "Bridget, Eva, and Annie"
date: "November 21, 2017"
output: pdf_document
---
```{r}
# read in the data
train_data=read.csv(file="/home/bridget/Dropbox/STATS202/kaggle/train.csv",header=T)
test_data=read.csv(file="/home/bridget/Dropbox/STATS202/kaggle/test.csv",header=T)

# check correlations
cor(train_data)

# plot relationship between Surface.Area and Rel.Compact
plot(train_data$Surface.Area,train_data$Rel.Compact)
# should drop one of these

# plot the relationship between Roof.Area and Height
plot(train_data$Roof.Area,train_data$Height)

# change height and orientation variables to categorical variables
#train_data$Height=as.factor(train_data$Height)
train_data$Orientation=as.factor(train_data$Orientation)

# remove ID variable since it just labels the rows
# remove relative compactness because it is linearly correlated with surface area
# remove surface area because it is equal to wall area + 2 *(roof area)
summary(lm(Surface.Area~Wall.Area+Roof.Area,data=train_data))

names(train_data)
train_data=train_data[,-c(1,2,3)]

# linear regression on remaining data
lm.fit=lm(Outcome~.,data=train_data)
summary(lm.fit)

# test whether we need all orientation variables
set.seed(1)
train_sample=sample(1:nrow(train_data),0.7*nrow(train_data))
lm.fit=lm(Outcome~.,data=train_data,subset=train_sample)
summary(lm.fit)
mean((predict(lm.fit,newdata=train_data[-train_sample,])-train_data[-train_sample,]$Outcome)^2)

train_sample=sample(1:nrow(train_data),0.7*nrow(train_data))
lm.fit=lm(Outcome~.-Orientation,data=train_data,subset=train_sample)
summary(lm.fit)
mean((predict(lm.fit,newdata=train_data[-train_sample,])-train_data[-train_sample,]$Outcome)^2)

# given that the validation set error is smaller for the model that does not include Orientation, 
# we drop orientation as well.

# test whether we need height/roof.area variable
lm.fit=lm(Outcome~.-Roof.Area-Orientation,data=train_data,subset=train_sample)
summary(lm.fit)
mean((predict(lm.fit,newdata=train_data[-train_sample,])-train_data[-train_sample,]$Outcome)^2)

lm.fit=lm(Outcome~.-Height-Orientation,data=train_data,subset=train_sample)
summary(lm.fit)
mean((predict(lm.fit,newdata=train_data[-train_sample,])-train_data[-train_sample,]$Outcome)^2)

# looks like we can drop the roof.area variable
# try adding an interaction term
lm.fit=lm(Outcome~.-Orientation+Wall.Area:Roof.Area,data=train_data,subset=train_sample)
summary(lm.fit)
mean((predict(lm.fit,newdata=train_data[-train_sample,])-train_data[-train_sample,]$Outcome)^2)

lm.fit=lm(Outcome~.-Roof.Area-Orientation+Wall.Area:Roof.Area,data=train_data,subset=train_sample)
summary(lm.fit)
mean((predict(lm.fit,newdata=train_data[-train_sample,])-train_data[-train_sample,]$Outcome)^2)

lm.fit=lm(Outcome~.-Roof.Area-Orientation+Wall.Area:Roof.Area+Roof.Area:Height,
          data=train_data,subset=train_sample)
summary(lm.fit)
mean((predict(lm.fit,newdata=train_data[-train_sample,])-train_data[-train_sample,]$Outcome)^2)

train_sample=sample(1:nrow(train_data),0.7*nrow(train_data))
lm.fit=lm(Outcome~.-Orientation+Wall.Area:Roof.Area,data=train_data,subset=train_sample)
summary(lm.fit)
mean((predict(lm.fit,newdata=train_data[-train_sample,])-train_data[-train_sample,]$Outcome)^2)
# this looks like a good model!
# check residuals/outliers/high leverage points
plot(lm.fit)
# there's weird structure in these residuals...

# try one more interaction term
train_sample=sample(1:nrow(train_data),0.7*nrow(train_data))
lm.fit=lm(Outcome~.-Orientation+Wall.Area:Roof.Area+Glazing.Distr:Glazing.Area,
          data=train_data,subset=train_sample)
summary(lm.fit)
mean((predict(lm.fit,newdata=train_data[-train_sample,])-train_data[-train_sample,]$Outcome)^2)

#########################################
# looks like the best regression model so far removes ID, relative compactness, surface area, 
# and Orientation, and adds Wall.Area*Roof.Area

# fit all of the data and make an output test set
names(train_data)
lm.fit=lm(Outcome~.-Orientation+Wall.Area:Roof.Area,data=train_data)
names(test_data)
ID=test_data$ID
test_data=test_data[,-c(1,2,3)]
test_data$Orientation=as.factor(test_data$Orientation)
out=data.frame(ID,predict(lm.fit,newdata=test_data))
names(out)=c("ID","Outcome")
write.csv(out, file = "test_linear_reg_bb_2017_11_21.csv",row.names=FALSE)

# leaderboard score was 2.98759.

```

```{r,fig.height=6}
# best subset selection
library(leaps)
n=ncol(train_sample)-1
regfit.full=regsubsets(Outcome~.,data=train_data,subset=train_sample,nvmax=n)
reg.summary=summary(regfit.full)
which.min(reg.summary$cp)
which.min(reg.summary$adjr2)
which.min(reg.summary$bic)
plot(regfit.full,scale="Cp")
plot(regfit.full,scale="adjr2")
plot(regfit.full, scale="bic")
# this roughly shows again that the orientation variable is not that useful.
```

```{r}
# random forest
library(randomForest)
set.seed(2)
# try on all of the data
train_data=read.csv(file="/home/bridget/Dropbox/STATS202/kaggle/train.csv",header=T)
names(train_data)
# remove ID
train_data=train_data[,-1]
n=ncol(train_data)-1
mse=rep(NA,n)
for (i in 1:n){
  rf.train=randomForest(Outcome~.,data=train_data,subset=train_sample,importance=TRUE,
                        ntree=1000,mtry=i)
  mse[i]=mean((predict(rf.train,newdata=train_data[-train_sample,])
               -train_data[-train_sample,]$Outcome)^2)
}
mse
importance(rf.train)

# try removing orientation
m=n-1
mse=rep(NA,m)
for (i in 1:m){
  rf.train=randomForest(Outcome~.-Orientation,data=train_data,subset=train_sample,
                        importance=TRUE,ntree=1000,mtry=i)
  mse[i]=mean((predict(rf.train,newdata=train_data[-train_sample,])
               -train_data[-train_sample,]$Outcome)^2)
}
mse
importance(rf.train)

# try interaction terms
new_train_data=data.frame(train_data,train_data$Wall.Area*train_data$Roof.Area)
mse=rep(NA,n)
for (i in 1:n){
rf.train=randomForest(Outcome~.-Orientation,data=new_train_data,subset=train_sample,
                      importance=TRUE,ntree=1000,mtry=i)
mse[i]=mean((predict(rf.train,newdata=new_train_data[-train_sample,])-
               new_train_data[-train_sample,]$Outcome)^2)
}
mse
importance(rf.train)
# looks like this is a good model with i = 6.

new_train_data=data.frame(train_data,train_data$Wall.Area*train_data$Glazing.Area)
mse=rep(NA,n)
for (i in 1:n){
rf.train=randomForest(Outcome~.,data=new_train_data,subset=train_sample,
                      importance=TRUE,ntree=1000,mtry=i)
mse[i]=mean((predict(rf.train,newdata=new_train_data[-train_sample,])
             -new_train_data[-train_sample,]$Outcome)^2)
}
mse
importance(rf.train)

mse=rep(NA,n)
for (i in 1:n){
rf.train=randomForest(Outcome~.,data=new_train_data,subset=train_sample,
                      importance=TRUE,ntree=1000,mtry=i,interaction_depth=4)
mse[i]=mean((predict(rf.train,newdata=new_train_data[-train_sample,])
             -new_train_data[-train_sample,]$Outcome)^2)
}
mse
importance(rf.train)

####################################################
new_train_data=data.frame(train_data,train_data$Wall.Area*train_data$Roof.Area)
names(new_train_data)
rf.train=randomForest(Outcome~.-Orientation,data=new_train_data,
                      importance=TRUE,ntree=1000,mtry=6)
test_data=read.csv(file="/home/bridget/Dropbox/STATS202/kaggle/test.csv",header=T)
ID=test_data$ID
test_data=test_data[,-1]
new_test_data=data.frame(test_data,test_data$Wall.Area*test_data$Roof.Area)
names(new_test_data)
names(new_test_data)[9]=names(new_train_data)[10]
out=data.frame(ID,predict(rf.train,newdata=new_test_data))
names(out)=c("ID","Outcome")
write.csv(out, file = "test_rand_forest_bb_2017_11_21.csv",row.names=FALSE)

# leaderboard score was 0.50795.
```
